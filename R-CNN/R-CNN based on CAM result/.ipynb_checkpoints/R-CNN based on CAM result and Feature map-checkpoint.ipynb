{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "\n",
    "import os\n",
    "\n",
    "import urllib.request as urllib2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "import copy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('aeroplane','bicycle','diningtable',\n",
    "           'dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor',\n",
    "           'bird','boat','bottle','bus','car','cat','chair','cow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAVE_IMAGE:\n",
    "    \n",
    "    def __init__(self, ncols = 0, nrows = 0, figTitle=\"\"):\n",
    "        \n",
    "        if ncols == 0 or nrows == 0:\n",
    "            raise ValueError(\"ncols and nrows must be initialize\")\n",
    "        \n",
    "        dpi = 80\n",
    "        height, width, depth = CV2_IMG.shape\n",
    "        figsize = width / float(dpi) * ncols , height / float(dpi) * nrows\n",
    "        self.fig, self.ax = plt.subplots(ncols = ncols, nrows = nrows, figsize=figsize)\n",
    "        self.ncols = ncols\n",
    "        self.nrows = nrows\n",
    "        \n",
    "        if figTitle is not \"\":\n",
    "            self.fig.suptitle(figTitle, fontsize=20)\n",
    "        self.ccols = 0\n",
    "        self.crows = 0\n",
    "        \n",
    "    def addImage(self, img, title = \"\"):\n",
    "        \n",
    "        if self.nrows == 1:\n",
    "            if self.ncols == 1:\n",
    "                self.ax.imshow(img)\n",
    "                self.ax.set_title(title, fontsize=15)\n",
    "            else:\n",
    "                self.ax[self.ccols].imshow(img)\n",
    "                self.ax[self.ccols].set_title(title, fontsize=15)\n",
    "        else:\n",
    "            self.ax[self.crows][self.ccols].imshow(img)\n",
    "            self.ax[self.crows][self.ccols].set_title(title, fontsize=15)\n",
    "\n",
    "        if self.ccols+1 == self.ncols:\n",
    "            self.crows = self.crows + 1\n",
    "            self.ccols = 0\n",
    "        else:\n",
    "            self.ccols = self.ccols + 1\n",
    "            \n",
    "    def showImage(self):\n",
    "        plt.show()\n",
    "        \n",
    "    def saveImage(self, save_path, save_title):\n",
    "        plt.savefig(save_path+save_title+'.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateRandomColor(num_of_class):\n",
    "    color = []\n",
    "\n",
    "    while len(color) < num_of_class:\n",
    "        r = random.randint(0,255)\n",
    "        g = random.randint(0,255)\n",
    "        b = random.randint(0,255)\n",
    "        rgb = [r,g,b]\n",
    "        color.append(rgb)\n",
    "    \n",
    "    return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckDirExists(PATH, DIR):\n",
    "    if not os.path.exists(PATH+DIR):\n",
    "        os.makedirs(PATH+DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveOriginalImage(img):\n",
    "    \n",
    "    save_image = SAVE_IMAGE(nrows = 1, ncols = 1, figTitle=\"base image\")\n",
    "    \n",
    "    save_image.addImage(img)\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, \"base_image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetHeatmap(img_list, height, width, title = \"\", figSet = False, fig = [0, 0]):\n",
    "    _title = \"_color_heatmap\"\n",
    "    heatmaps = []\n",
    "    \n",
    "    if figSet:\n",
    "        save_image = SAVE_IMAGE(nrows = fig[0], ncols = fig[1], figTitle=title+_title)\n",
    "    else: \n",
    "        save_image = SAVE_IMAGE(nrows = 1, ncols = len(img_list), figTitle=title+_title)\n",
    "    \n",
    "    for index, img in enumerate(img_list):\n",
    "        heatmap = cv2.applyColorMap(cv2.resize(img, (width, height)), cv2.COLORMAP_JET)\n",
    "        heatmaps.append(heatmap)\n",
    "        tmp_img = heatmap*0.6 + CV2_IMG*0.4\n",
    "        save_image.addImage(cv2.cvtColor(np.float32(tmp_img).astype('uint8'), cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, title+_title)\n",
    "    \n",
    "    return heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_img에서 (R, G, B) 세 가지 채널의 정보 중 특정 채널의 정보만 남겨서 넘김\n",
    "def GetChannelImage(orig_img, channel):\n",
    "    channel = channel.upper()\n",
    "    channel_img = orig_img.copy()\n",
    "    if channel == 'R':\n",
    "        channel_img[:, :, 0] = 0\n",
    "        channel_img[:, :, 1] = 0\n",
    "    elif channel == 'G':\n",
    "        channel_img[:, :, 0] = 0\n",
    "        channel_img[:, :, 2] = 0\n",
    "    elif channel == 'B':\n",
    "        channel_img[:, :, 1] = 0\n",
    "        channel_img[:, :, 2] = 0\n",
    "\n",
    "    return channel_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color image를 gray scale로 바꾼 후, threshold를 적용함\n",
    "# threshold는 고정 값으로 mean(min, max)\n",
    "def GetGrayscaleImageWithThreshold(orig_img):\n",
    "    gray_img = cv2.cvtColor(orig_img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    min_val = np.min(gray_img)\n",
    "    max_val = np.max(gray_img)\n",
    "    threshold = (min_val + max_val) / 2\n",
    "    \n",
    "    ret, gray_img = cv2.threshold(gray_img, threshold, 1, cv2.THRESH_BINARY)    \n",
    "\n",
    "    return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale_mask 에서 1인 부분만 orig_img를 보여줌. 0인 부분은 검정색으로 보임\n",
    "def GetMaskedImage(orig_img, gray_map):\n",
    "    mask = cv2.cvtColor(gray_map, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    maskedRegion = np.where(mask == 1, orig_img, 0)\n",
    "    \n",
    "    return cv2.cvtColor(maskedRegion, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGrayscaleHeatmap(heatmaps, title = \"\", figSet = False, fig = [0, 0]):\n",
    "    _title = \"_grayscale_heatmap\"\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    for index, heatmap in enumerate(heatmaps):\n",
    "        # heatmap에서 R channel만 뽑아냄\n",
    "        tmp = GetChannelImage(heatmap, 'r')\n",
    "        # grayscale로 변환 후 threshold 적용\n",
    "        result.append(GetGrayscaleImageWithThreshold(tmp))\n",
    "    \n",
    "    if figSet:\n",
    "        save_image = SAVE_IMAGE(nrows = fig[0], ncols = fig[1], figTitle=title+_title)\n",
    "    else:\n",
    "        save_image = SAVE_IMAGE(nrows = 1, ncols = len(result), figTitle=title+_title)\n",
    "    \n",
    "    for index, graymap in enumerate(result):\n",
    "        save_image.addImage(GetMaskedImage(CV2_IMG, graymap))\n",
    "    \n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, title+_title)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetContours(img_binary):\n",
    "    contours, hierarchy = cv2.findContours(img_binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetBBox(img_binary):\n",
    "    bb = []\n",
    "    \n",
    "    contours = GetContours(img_binary)\n",
    "    \n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        bb.append([x, y, w, h])\n",
    "        \n",
    "    return bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawBBox(bounding_box, img):\n",
    "    tmp_img = img.copy()\n",
    "\n",
    "    dim = np.array(bounding_box).ndim\n",
    "    \n",
    "    if dim == 2:\n",
    "        for x, y, w, h in bounding_box:\n",
    "            cv2.rectangle(tmp_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    elif dim == 3:\n",
    "        for bb in bounding_box:\n",
    "            for x, y, w, h in bb:\n",
    "                cv2.rectangle(tmp_img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "    return cv2.cvtColor(tmp_img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawContourAndBBox(img_binary, img):\n",
    "    contours = GetContours(img_binary)\n",
    "    \n",
    "    tmp_img = img.copy()\n",
    "    \n",
    "    # draw contours - red\n",
    "    for cnt in contours:\n",
    "        cv2.drawContours(tmp_img, [cnt], 0, (0,0,255),3)\n",
    "    \n",
    "    # draw bounding box - green\n",
    "    bb = GetBBox(img_binary)\n",
    "    \n",
    "    for x, y, w, h in bb:\n",
    "        cv2.rectangle(tmp_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "        \n",
    "    return cv2.cvtColor(tmp_img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareContourAndBBox(heatmaps, title = \"\", figSet = False, fig = [0, 0]):\n",
    "    _title = \"_contour\"\n",
    "    \n",
    "    if figSet:\n",
    "        save_image = SAVE_IMAGE(nrows = fig[0], ncols = fig[1], figTitle=title+_title)\n",
    "    else:\n",
    "        save_image = SAVE_IMAGE(nrows = 1, ncols = len(heatmaps), figTitle=title+_title)\n",
    "    for index, heatmap in enumerate(heatmaps):\n",
    "        save_image.addImage(DrawContourAndBBox(heatmap, CV2_IMG))\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, title+_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetIOU(_bb1, _bb2, changeScale = False, basedOnCAM = False):\n",
    "    # _bb2 == cam_bb\n",
    "    if changeScale:\n",
    "        # _bb1, _bb2 = [x, y, w, h]\n",
    "        if len(_bb1) == 4 and len(_bb2) == 4:\n",
    "            bb1 = {'x1':_bb1[0], 'y1':_bb1[1], 'x2':_bb1[0]+_bb1[2], 'y2':_bb1[1]+_bb1[3]}\n",
    "            bb2 = {'x1':_bb2[0], 'y1':_bb2[1], 'x2':_bb2[0]+_bb2[2], 'y2':_bb2[1]+_bb2[3]}\n",
    "        else:\n",
    "            exit(0)\n",
    "    else:\n",
    "        # _bb1, _bb2 = ['x1':x1, 'x2':x2, 'y1':y1, 'y2':y2]\n",
    "        x1, y1, x2, y2 = _bb1\n",
    "        bb1 = {\"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2}\n",
    "        x1, y1, x2, y2 = _bb2\n",
    "        bb2 = {\"x1\": x1, \"y1\": y1, \"x2\": x2, \"y2\": y2}\n",
    "    \n",
    "    \n",
    "    assert bb1['x1'] < bb1['x2']\n",
    "    assert bb1['y1'] < bb1['y2']\n",
    "    assert bb2['x1'] < bb2['x2']\n",
    "    assert bb2['y1'] < bb2['y2']\n",
    "    \n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(bb1['x1'], bb2['x1'])\n",
    "    y_top = max(bb1['y1'], bb2['y1'])\n",
    "    x_right = min(bb1['x2'], bb2['x2'])\n",
    "    y_bottom = min(bb1['y2'], bb2['y2'])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    # The intersection of two axis-aligned bounding boxes is always an\n",
    "    # axis-aligned bounding box\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the area of both AABBs\n",
    "    bb1_area = (bb1['x2'] - bb1['x1']) * (bb1['y2'] - bb1['y1'])\n",
    "    bb2_area = (bb2['x2'] - bb2['x1']) * (bb2['y2'] - bb2['y1'])\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    \n",
    "    if basedOnCAM:\n",
    "        # cam_bb 기준 iou\n",
    "        iou = intersection_area / float(bb2_area)\n",
    "    else:\n",
    "        iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    \n",
    "    assert iou >= 0.0\n",
    "    assert iou <= 1.0\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isExist(bounding_box, bb):\n",
    "    for _bb in bounding_box:\n",
    "        if np.array_equal(_bb, bb):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCandidateBBox(FM_BB, CAM_BB):\n",
    "    # FM_BB dim = 2\n",
    "    # CAM_BB dim = 2\n",
    "    \n",
    "    bounding_box = []\n",
    "\n",
    "    for fm_bb in FM_BB:\n",
    "        for cam_bb in CAM_BB:\n",
    "            iou = GetIOU(fm_bb, cam_bb, changeScale = True, basedOnCAM=True)\n",
    "            if iou > 0.7:\n",
    "                if not isExist(bounding_box, fm_bb):\n",
    "                    bounding_box.append(fm_bb)\n",
    "                \n",
    "    return bounding_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMS(bounding_box, probs):\n",
    "    \n",
    "    bbox = []\n",
    "\n",
    "    for x, y, w, h in bounding_box:\n",
    "        bbox.append([x,y, x+w, y+h])\n",
    "    \n",
    "    \n",
    "    _opencvImg = img.copy()\n",
    "    bbox = torch.as_tensor(bbox).float()\n",
    "    probs = torch.as_tensor(probs)\n",
    "    for c in range(len(classes)):\n",
    "        \n",
    "        _cnt = 0\n",
    "        \n",
    "        # threshold 적용\n",
    "        \n",
    "        prob = probs[:, c].clone()\n",
    "        \n",
    "        m = nn.Threshold(0.2, 0)\n",
    "        \n",
    "        prob = m(prob)\n",
    "        \n",
    "        order = torch.argsort(prob, descending=True)\n",
    "        \n",
    "        for i in range(len(order)):\n",
    "            printProgressBar (i, len(order), prefix = f'class {c}', suffix = 'complete', length = 50)\n",
    "            bbox_max = bbox[order[i]]\n",
    "            for j in range(i+1, len(order)):\n",
    "                bbox_cur = bbox[order[j]]\n",
    "                \n",
    "                if get_iou(bbox_max, bbox_cur) > 0.5:\n",
    "                    prob[order[j]] = 0\n",
    "        \n",
    "        printProgressBar (len(order), len(order), prefix = f'class {c}', suffix = 'complete', length = 50)\n",
    "        probs[:, c] = prob\n",
    "        \n",
    "    return probs\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawResultByClass(bounding_box, probs, fig = [5, 4]):\n",
    "    \n",
    "    _opencvImg = CV2_IMG.copy()\n",
    "    save_image = SAVE_IMAGE(nrows = fig[0], ncols = fig[1], figTitle=\"\")\n",
    "    \n",
    "    for i in range(20):\n",
    "        row = int(i / 5)\n",
    "        col = i % 5\n",
    "        \n",
    "        _opencvImg = CV2_IMG.copy()\n",
    "        \n",
    "        draw = 0\n",
    "        \n",
    "        for cnt in range(len(bounding_box)):\n",
    "            \n",
    "            cls_idx = torch.argsort(probs[cnt, :], descending=True)[0]\n",
    "            if cls_idx == i:\n",
    "                if probs[cnt][cls_idx] > 0:\n",
    "                    draw += 1\n",
    "                    x,y,w,h = bounding_box[cnt]\n",
    "                    _opencvImg = cv2.rectangle(_opencvImg, (x, y,), (x+w, y+h), color[cls_idx], 3)\n",
    "                    text = '{} ({:.3f})'.format(classes[cls_idx], probs[cnt][cls_idx])\n",
    "                    cv2.putText(_opencvImg, text, (x, y+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color[cls_idx], 2)\n",
    "        \n",
    "        title = classes[i] + \": \"+str(draw)\n",
    "        save_image.addImage(cv2.cvtColor(_opencvImg, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, \"draw_result_by_class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawResult(bounding_box, probs):\n",
    "    \n",
    "    draw = 0\n",
    "    _opencvImg = img.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for cnt in range(len(bounding_box)):\n",
    "        \n",
    "        cls_idx = torch.argsort(probs[cnt, :], descending=True)[0]\n",
    "        \n",
    "        if probs[cnt][cls_idx] > 0:\n",
    "            print(f'class {classes[cls_idx]}: {probs[cnt][cls_idx]}')\n",
    "            draw += 1\n",
    "            x,y,w,h = bounding_box[cnt]\n",
    "            _opencvImg = cv2.rectangle(_opencvImg, (x, y,), (x+w, y+h), color[cls_idx], 2)\n",
    "            text = '{} ({:.3f})'.format(classes[cls_idx], probs[cnt][cls_idx])\n",
    "            cv2.putText(_opencvImg, text, (x, y+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color[cls_idx], 1) \n",
    "            \n",
    "    \n",
    "    title = f'final bbox: {draw}'\n",
    "    save_image = SAVE_IMAGE(nrows = 1, ncols = 1, figTitle=title)\n",
    "    save_image.addImage(cv2.cvtColor(_opencvImg, cv2.COLOR_BGR2RGB), title=\"\")\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, title=\"final_bbox\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_CNN(IMG_URL, CAM_RESULT, FEATURE_MAP, fig = [0, 0]):\n",
    "    \n",
    "    \n",
    "    global RESULT_PATH, RESULT_DIR, PIL_IMG, CV2_IMG\n",
    "    RESULT_PATH = './Result/'\n",
    "    RESULT_DIR = 'test/'\n",
    "    \n",
    "    # check and make result dir to save result\n",
    "    CheckDirExists(RESULT_PATH, RESULT_DIR)\n",
    "    \n",
    "    # load image\n",
    "    PIL_IMG = Image.open(urllib2.urlopen(IMG_URL))\n",
    "    CV2_IMG = cv2.cvtColor(np.array(PIL_IMG), cv2.COLOR_RGB2BGR)\n",
    "    height, width, depth = CV2_IMG.shape\n",
    "    \n",
    "    # save base image\n",
    "    save_image = SAVE_IMAGE(nrows = 1, ncols = 1, figTitle=\"base image\")\n",
    "    save_image.addImage(cv2.cvtColor(CV2_IMG, cv2.COLOR_BGR2RGB))\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, \"base_image\")\n",
    "    \n",
    "    # get CAM result bbox\n",
    "    \n",
    "    ## heatmap 얻기\n",
    "    CAM_heatmaps = GetHeatmap(CAM_RESULT, height, width, 'CAM')\n",
    "    CAM_heatmaps = GetGrayscaleHeatmap(CAM_heatmaps, 'CAM')\n",
    "    \n",
    "    ## contour와 bbox 비교 이미지 얻기\n",
    "    CompareContourAndBBox(CAM_heatmaps, 'CAM')\n",
    "    \n",
    "    ## bbox 얻기\n",
    "    CAM_BB = []\n",
    "    for index, heatmap in enumerate(CAM_heatmaps):\n",
    "        tmp_bb = GetBBox(heatmap)\n",
    "        for index2, bbox in enumerate(tmp_bb):\n",
    "            CAM_BB.append(bbox)\n",
    "       \n",
    "    title = \"CAM_BBOX: \"+str(len(CAM_BB))\n",
    "    save_image = SAVE_IMAGE(nrows = 1, ncols = 1, figTitle=title)\n",
    "    save_image.addImage(DrawBBox(CAM_BB, CV2_IMG))\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, \"CAM_BBOX\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get FeatureMap bbox\n",
    "    \n",
    "    ## heatmap 얻기\n",
    "    FM_heatmaps = GetHeatmap(FEATURE_MAP, height, width, 'FM', figSet = True, fig = fig)\n",
    "    FM_heatmaps = GetGrayscaleHeatmap(FM_heatmaps, 'FM', figSet = True, fig = fig)\n",
    "    \n",
    "    ## contour와 bbox 비교 이미지 얻기\n",
    "    CompareContourAndBBox(FM_heatmaps, 'FM', figSet = True, fig = fig)\n",
    "    \n",
    "    ## bbox 얻기\n",
    "    FM_BB = []\n",
    "    for index, heatmap in enumerate(FM_heatmaps):\n",
    "        tmp_bb = GetBBox(heatmap)\n",
    "        for index2, bbox in enumerate(tmp_bb):\n",
    "            FM_BB.append(bbox)\n",
    "      \n",
    "    title = \"FM_BBOX: \"+str(len(FM_BB))\n",
    "    save_image = SAVE_IMAGE(nrows = 1, ncols = 1, figTitle=title)\n",
    "    save_image.addImage(DrawBBox(FM_BB, CV2_IMG))\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, \"FM_BBOX\")\n",
    "\n",
    "    # get candidate bbox with CAM bbox and FeatureMap bbox\n",
    "    candidate_bbox = GetCandidateBBox(FM_BB, CAM_BB)\n",
    "    title = \"candidate_bbox: \"+str(len(candidate_bbox))\n",
    "    save_image = SAVE_IMAGE(nrows = 1, ncols = 1, figTitle=title)\n",
    "    save_image.addImage(DrawBBox(candidate_bbox, CV2_IMG))\n",
    "    save_image.saveImage(RESULT_PATH+RESULT_DIR, \"candidate_bbox\")\n",
    "    \n",
    "    # R-CNN\n",
    "    \n",
    "    ## load model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 20)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load('../PASCAL VOC 2012 R-CNN/TrainedModel/ResNet_pretrained_True'))\n",
    "    model.eval()\n",
    "    \n",
    "    det_probs = []\n",
    "\n",
    "    for index, (x, y, w, h) in enumerate(candidate_bbox):\n",
    "        area = (x, y, x + w, y + h)\n",
    "        timage = PIL_img.crop(area)\n",
    "        timage = data_transforms['test'](transforms.ToPILImage()(np.asarray(timage)))\n",
    "        prob = get_predict(model, timage)\n",
    "        det_probs.append(prob.tolist()[0])\n",
    "\n",
    "    det_probs = torch.as_tensor(det_probs)\n",
    "    \n",
    "    final_probs = NMS(bounding_box, det_probs)\n",
    "    DrawResult(bounding_box, final_probs)\n",
    "    DrawResultByClass(bounding_box, final_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
