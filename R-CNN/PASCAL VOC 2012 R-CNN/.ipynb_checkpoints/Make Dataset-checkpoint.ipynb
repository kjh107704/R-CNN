{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import ImageFolder\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "\n",
    "import xml.etree.ElementTree as Et\n",
    "from xml.etree.ElementTree import Element, ElementTree\n",
    "\n",
    "import random\n",
    "\n",
    "import shutil\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█', printEnd = \"\\r\"):\n",
    "    \"\"\"\n",
    "    Call in a loop to create terminal progress bar\n",
    "    @params:\n",
    "        iteration   - Required  : current iteration (Int)\n",
    "        total       - Required  : total iterations (Int)\n",
    "        prefix      - Optional  : prefix string (Str)\n",
    "        suffix      - Optional  : suffix string (Str)\n",
    "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
    "        length      - Optional  : character length of bar (Int)\n",
    "        fill        - Optional  : bar fill character (Str)\n",
    "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
    "    \"\"\"\n",
    "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "    filledLength = int(length * iteration // total)\n",
    "    bar = fill * filledLength + '-' * (length - filledLength)\n",
    "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
    "    # Print New Line on Complete\n",
    "    if iteration == total: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['aeroplane', 'bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike'\n",
    ",'person','pottedplant','sheep','sofa','train','tvmonitor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training dataset 만들기\n",
    "\n",
    "PASCAL VOC 2012(class 20개) 데이터 사용함.\n",
    "\n",
    "Annotation이 존재하는 모든 이미지에서 object를 crop한 뒤,\n",
    "각 class 별로 train: 최대 800개, val: 100개, test: 100개 이미지를 가지도록 split 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경로 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수정 x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASCAL VOC DATASET JPEGImages 경로\n",
    "IMAGE_PATH = 'JPEGImages/'\n",
    "# PASCAL VOC DATASET Annotations 경로\n",
    "ANNOTATION_PATH = 'Annotations/'\n",
    "\n",
    "\n",
    "# 만든 dataset 저장할 최상위 폴더 (base 폴더가 존재하는 경로)\n",
    "DATASET_PATH = './Dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수정 가능 path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original PASCAL VOC dataset 경로 (JPEGImages, Annotation 들어있는 상위 폴더) (수정 0)\n",
    "PASCAL_PATH = './VOCtrainval_11-May-2012/VOCdevkit/VOC2012/'\n",
    "\n",
    "# train, val, test 폴더가 존재할 경로\n",
    "# main 함수에서 수정\n",
    "CUSTOM_PATH = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeNumOfImg():\n",
    "    for i in range(20):\n",
    "        num_of_img[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_img = {}\n",
    "InitializeNumOfImg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지를 지정된 폴더에 저장\n",
    "    \n",
    "- base img (전체 데이터 편집 시 사용): DATASET_PATH/base/class번호/ 폴더 내부에 이미지 저장\n",
    "\n",
    "- train img: DATASET_PATH/train/class번호/ 폴더 내부에 이미지 저장\n",
    "    \n",
    "- val img: DATASET_PATH/val/class번호/ 폴더 내부에 이미지 저장\n",
    "    \n",
    "- test img: DATASET_PATH/test/class번호/ 폴더 내부에 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_imsave(img, label, mode = 'base'):\n",
    "    \n",
    "    if mode == 'train' or mode == 'trainval':\n",
    "        path = DATASET_PATH + CUSTOM_PATH + 'train/' + str(label) + '/'\n",
    "    elif mode == 'val':\n",
    "        path = DATASET_PATH + CUSTOM_PATH + 'val/' + str(label) + '/'\n",
    "    elif mode == 'test':\n",
    "        path = DATASET_PATH + CUSTOM_PATH + 'test/' + str(label) + '/'\n",
    "    elif mode == 'base':\n",
    "        path = DATASET_PATH + 'base/' + str(label) + '/'\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    cv2.imwrite(path+str(num_of_img[label])+'.jpg', img)\n",
    "    num_of_img[label] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation이 존재하는 모든 이미지를 crop하여 class별로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_base_dataset():\n",
    "    mypath = PASCAL_PATH+'/Annotations'\n",
    "    img_list = [f.split('.')[0] for f in os.listdir(mypath) if f.endswith('.xml')]\n",
    "    print(f'total image: {len(img_list)}')\n",
    "    \n",
    "    for index, img_name in enumerate(img_list):\n",
    "        printProgressBar(index, len(img_list), prefix='Progress', suffix='Complete', length=50)\n",
    "        tmp_img = cv2.imread(PASCAL_PATH+IMAGE_PATH+'/'+img_name+'.jpg')\n",
    "        imout = tmp_img.copy()\n",
    "\n",
    "        gtvalues = []\n",
    "\n",
    "        img_xml = open(PASCAL_PATH+ANNOTATION_PATH+'/'+img_name+'.xml')\n",
    "        tree = Et.parse(img_xml)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        objects = root.findall(\"object\")\n",
    "\n",
    "        # Annotation 기준으로 object 추출\n",
    "        for _object in objects:\n",
    "            name = _object.find(\"name\").text\n",
    "            bndbox = _object.find(\"bndbox\")\n",
    "            xmin = int(float(bndbox.find(\"xmin\").text))\n",
    "            ymin = int(float(bndbox.find(\"ymin\").text))\n",
    "            xmax = int(float(bndbox.find(\"xmax\").text))\n",
    "            ymax = int(float(bndbox.find(\"ymax\").text))\n",
    "            \n",
    "            timage = imout[ymin:ymax, xmin:xmax]\n",
    "            # 정의된 class에 존재하는 object일 경우 이미지 crop 및 저장\n",
    "            if name in classes:\n",
    "                class_num = classes.index(name)\n",
    "                custom_imsave(timage, class_num, mode = 'base')\n",
    "    printProgressBar(len(img_list), len(img_list), prefix='Progress', suffix='Complete', length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_into_train_val_test(excludedClass = [],ratio = False, ratioRange = \"\", size = False, sizeLimit = \"\"):\n",
    "    \n",
    "    CUSTOM_PATH = \"\"\n",
    "    \n",
    "    if ratio:\n",
    "        if not isinstance(ratioRange, list):\n",
    "            raise ValueError(\"ratioRange must be a list type\")\n",
    "        if not len(ratioRange) == 2:\n",
    "            raise ValueError(\"ratioRange must have a two value: [minRatio, maxRatio]\")\n",
    "        CUSTOM_PATH += f'ratio_{str(ratioRange[0])}_{str(ratioRange[1])}'\n",
    "    if size:\n",
    "        if not isinstance(sizeLimit, int):\n",
    "            raise ValueError(\"size must be a int type\")\n",
    "        if CUSTOM_PATH is not \"\":\n",
    "            CUSTOM_PATH += \"_\"\n",
    "        CUSTOM_PATH += f'minSize_{sizeLimit}'\n",
    "    \n",
    "    if CUSTOM_PATH is \"\":\n",
    "        CUSTOM_PATH = 'all'\n",
    "    \n",
    "    \n",
    "    if os.path.exists(DATASET_PATH + CUSTOM_PATH):\n",
    "        shutil.rmtree(DATASET_PATH + CUSTOM_PATH)\n",
    "    \n",
    "    path_list = ['train/', 'val/', 'test/', 'out_of_condition/']\n",
    "    condition_list = ['size/', 'aspectRatio/', 'both']\n",
    "    \n",
    "    for path in path_list:\n",
    "        if not os.path.exists(os.path.join(DATASET_PATH, CUSTOM_PATH, path)):\n",
    "            os.makedirs(os.path.join(DATASET_PATH, CUSTOM_PATH, path))\n",
    "            \n",
    "            for i in num_of_img:\n",
    "                if not os.path.exists(os.path.join(DATASET_PATH, CUSTOM_PATH,path,str(i))):\n",
    "                    os.makedirs(os.path.join(DATASET_PATH, CUSTOM_PATH,path,str(i)))\n",
    "                    if path is path_list[3]:\n",
    "                        for name in condition_list:\n",
    "                            os.makedirs(os.path.join(DATASET_PATH, CUSTOM_PATH,path,str(i), name))\n",
    "    \n",
    "    for i in range(20):\n",
    "        \n",
    "        if i in excludedClass:\n",
    "            print(f'class {i} is in excludedClass')        \n",
    "        \n",
    "        cnt = 0\n",
    "        class_path = os.path.join(DATASET_PATH+'base/',str(i))\n",
    "        img_list = [f for f in os.listdir(class_path)]\n",
    "        #print(f'class {i} has {len(img_list)} items (total)')\n",
    "        random.shuffle(img_list)\n",
    "        \n",
    "        candidate_img_list = []\n",
    "        \n",
    "        for index, img_name in enumerate(img_list):\n",
    "            #printProgressBar(index, len(img_list), prefix=f'Class {i}', suffix='Complete', length=50)\n",
    "            \n",
    "        \n",
    "            img = cv2.imread(os.path.join(class_path,img_name))\n",
    "            \n",
    "            minSize = min(img.shape[0], img.shape[1])\n",
    "            maxSize = max(img.shape[0], img.shape[1])\n",
    "            imgRatio = float(img.shape[1]) / img.shape[0]\n",
    "            \n",
    "            flag = \"\"\n",
    "            \n",
    "            if i not in excludedClass:\n",
    "            \n",
    "                if ratio and not (ratioRange[0] <= imgRatio and imgRatio <= ratioRange[1]):\n",
    "                    flag = 'aspectRatio'\n",
    "                    #print(f'({img.shape[1]}, {img.shape[0]}) , ratio = {imgRatio}')\n",
    "                if size and not (sizeLimit < minSize):\n",
    "                    #print(f'minSize = {minSize}')\n",
    "                    if flag is \"\":\n",
    "                        flag = 'size'\n",
    "                    elif flag is 'aspectRatio':\n",
    "                        flag = 'both'\n",
    "                    \n",
    "                if flag is 'size':\n",
    "                    copyfile(os.path.join(class_path,img_name),os.path.join(DATASET_PATH, CUSTOM_PATH, path_list[3],str(i), condition_list[0],img_name))\n",
    "                    continue\n",
    "                elif flag is 'aspectRatio':\n",
    "                    copyfile(os.path.join(class_path,img_name),os.path.join(DATASET_PATH, CUSTOM_PATH, path_list[3],str(i), condition_list[1],img_name))\n",
    "                    continue\n",
    "                elif flag is 'both':\n",
    "                    copyfile(os.path.join(class_path,img_name),os.path.join(DATASET_PATH, CUSTOM_PATH, path_list[3],str(i), condition_list[2],img_name))\n",
    "                    continue\n",
    "                \n",
    "            candidate_img_list.append(img_list)\n",
    "            \n",
    "            if cnt < 50:\n",
    "                copyfile(os.path.join(class_path,img_name),os.path.join(DATASET_PATH, CUSTOM_PATH, path_list[1],str(i),img_name))\n",
    "            elif cnt < 80:\n",
    "                copyfile(os.path.join(class_path,img_name),os.path.join(DATASET_PATH, CUSTOM_PATH, path_list[2],str(i),img_name))\n",
    "            elif cnt < 1000:\n",
    "                copyfile(os.path.join(class_path,img_name),os.path.join(DATASET_PATH, CUSTOM_PATH, path_list[0],str(i),img_name))\n",
    "                \n",
    "            cnt += 1\n",
    "        print(f'class {i} has {len(candidate_img_list)} items (candidate)')\n",
    "                \n",
    "        #printProgressBar(len(img_list), len(img_list), prefix=f'Class {i}', suffix='Complete', length=50)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class 목록\n",
    "\n",
    "0: aeroplane\n",
    "\n",
    "1: bicycle\n",
    "\n",
    "2: bird\n",
    "\n",
    "3: boat\n",
    "\n",
    "4: bottle\n",
    "\n",
    "5: bus\n",
    "\n",
    "6: car\n",
    "\n",
    "7: cat\n",
    "\n",
    "8: chair\n",
    "\n",
    "9: cow\n",
    "\n",
    "10: dining table\n",
    "\n",
    "11: dog\n",
    "\n",
    "12: horse\n",
    "\n",
    "13: motorbike\n",
    "\n",
    "14: person\n",
    "\n",
    "15: pottedplant\n",
    "\n",
    "16: sheep\n",
    "\n",
    "17: sofa\n",
    "\n",
    "18: train\n",
    "\n",
    "19: tvmonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base already exists, skip make_base_dataset()\n",
      "class 0 is in excludedClass\n",
      "class 0 has 1002 items (candidate)\n",
      "class 1 has 425 items (candidate)\n",
      "class 2 has 570 items (candidate)\n",
      "class 3 has 237 items (candidate)\n",
      "class 4 is in excludedClass\n",
      "class 4 has 1561 items (candidate)\n",
      "class 5 has 308 items (candidate)\n",
      "class 6 has 462 items (candidate)\n",
      "class 7 has 910 items (candidate)\n",
      "class 8 has 1560 items (candidate)\n",
      "class 9 has 342 items (candidate)\n",
      "class 10 has 264 items (candidate)\n",
      "class 11 has 1149 items (candidate)\n",
      "class 12 has 511 items (candidate)\n",
      "class 13 has 430 items (candidate)\n",
      "class 14 is in excludedClass\n",
      "class 14 has 17401 items (candidate)\n",
      "class 15 has 421 items (candidate)\n",
      "class 16 has 417 items (candidate)\n",
      "class 17 has 378 items (candidate)\n",
      "class 18 has 258 items (candidate)\n",
      "class 19 has 525 items (candidate)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if not os.path.exists(DATASET_PATH + 'base/'):\n",
    "        make_base_dataset()\n",
    "    else:\n",
    "        print('base already exists, skip make_base_dataset()')\n",
    "    \n",
    "    excludedClass = [0, 4, 14]\n",
    "    \n",
    "    # 기준별로 저장 경로가 알아서 바뀜\n",
    "    ## ratio,size 기준 없는 경우: DATASET_PATH + all/\n",
    "    ## ratio 기준 있는 경우: DATASET_PATH + ratio_{str(ratioRange[0])}_{str(ratioRange[1])}\n",
    "    ## minsize 기준 있는 경우: DATASET_PATH + minSize_{sizeLimit}\n",
    "    ## 두 기준 모두 적용: DATASET_PATH + ratio_{str(ratioRange[0])}_{str(ratioRange[1])}_minSize_{sizeLimit}\n",
    "    split_data_into_train_val_test(excludedClass = excludedClass, ratio = True, ratioRange = [0.5, 1.5], size = True, sizeLimit = 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
